{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras import layers, Model\nfrom keras.optimizers import SGD\n\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = load_img('test.jpg')\nimage = img_to_array(image)\nimage = expand_dims(image, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=30,\n    shear_range=0.5,\n    zoom_range=0.5,\n    horizontal_flip=True,\n    vertical_flip=True,\n)\n# iterator = datagen.flow(image, batch_size=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(5, 2, figsize=(15, 25))\naxs = axs.ravel()\nfor i in range(10):\n    batch = iterator.next()\n    new_image = batch[0].astype('uint8')\n    axs[i].imshow(new_image)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(x_train,y_train),(x_test,y_test) = cifar10.load_data()\nn_classes = 10\n\ny_train = keras.utils.to_categorical(y_train,n_classes)\ny_test = keras.utils.to_categorical(y_test,n_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_indices = [i for i, y in enumerate(y_train) if  y[3] == 1]\ndog_indices = [i for i, y in enumerate(y_train) if  y[5] == 1]\ndeleted_cat = np.random.choice(cat_indices, size=4500, replace=False)\ndeleted_dog = np.random.choice(dog_indices, size=4500, replace=False)\ndeleted_indices = np.concatenate((deleted_cat, deleted_dog))\n\ny_train = np.delete(y_train, deleted_indices, axis=0)\nx_train = np.delete(x_train, deleted_indices, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"input_layer = layers.Input (shape=(32,32,3))\n\nconv1 = layers.Conv2D (16, (3, 3), activation='relu', padding='same', strides=1)(input_layer)\nconv2 = layers.Conv2D (32, (3, 3), activation='relu', padding='same', strides=1)(conv1)\npool1 = layers.MaxPool2D(pool_size=(2, 2))(conv2)\n\nconv3 = layers.Conv2D (32, (3, 3), activation='relu', padding='same', strides=1)(pool1)\nconv4 = layers.Conv2D (64, (3, 3), activation='relu', padding='same', strides=1)(conv3)\npool2 = layers.MaxPool2D(pool_size=(2, 2))(conv4)\n\nconv5 = layers.Conv2D (64, (3, 3), activation='relu', padding='same', strides=1)(pool2)\nconv6 = layers.Conv2D (128, (3, 3), activation='relu', padding='same', strides=1)(conv5)\npool3 = layers.MaxPool2D(pool_size=(2, 2))(conv6)\n\ndrop1 = layers.Dropout(0.2)(pool3)\n\nflatten = layers.Flatten()(drop1)\n\nfully_connected1 = layers.Dense(300,activation = 'relu')(flatten)\ndrop2 = layers.Dropout(0.3)(fully_connected1)\nfully_connected2 = layers.Dense(100,activation = 'relu')(drop2)\ndrop3 = layers.Dropout(0.3)(fully_connected2)\nfully_connected3 = layers.Dense(10,activation = 'softmax')(drop3)\n\nmodel = Model(input_layer, fully_connected3)\n\nmodel.summary()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, batch_size=128, epochs=50)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(x_test)\nprediction = [np.argmax(y) for y in prediction]\nlabels = [np.argmax(y) for y in y_test]\n\ncm = confusion_matrix(labels, prediction)\nsns.heatmap(cm/np.sum(cm), cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(labels, prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_indices = [i for i, y in enumerate(y_train) if  y[3] == 1]\ndog_indices = [i for i, y in enumerate(y_train) if  y[5] == 1]\n\ncats = x_train[cat_indices]\ndogs = x_train[dog_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_category(datagen, category_data, category_index):\n    \n    datagen.fit(category_data)\n    iterator = datagen.flow(category_data, batch_size=1)\n    new_data = []\n    for i in range(4500):\n        new_data.append(iterator.next()[0])\n\n    label = [0 for _ in range(10)]\n    label[category_index] = 1\n    labels = [label for sample in new_data]\n    \n    return new_data, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_cat, cat_labels = augment_category(datagen, cats, 3)\nnew_dog, dog_labels = augment_category(datagen, dogs, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.concatenate((x_train, new_cat))\ny_train = np.concatenate((y_train, cat_labels))\n\nx_train = np.concatenate((x_train, new_dog))\ny_train = np.concatenate((y_train, dog_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = np.array([i for i in range(len(x_train))])\nindices = np.random.shuffle(indices)\nx_train = x_train[indices].reshape((50000, 32, 32, 3))\ny_train = y_train[indices].reshape((50000, 10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}